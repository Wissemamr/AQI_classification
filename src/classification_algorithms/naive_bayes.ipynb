{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>AQI Category</th>\n",
       "      <th>CO AQI Value</th>\n",
       "      <th>Ozone AQI Value</th>\n",
       "      <th>Ozone AQI Category</th>\n",
       "      <th>NO2 AQI Value</th>\n",
       "      <th>PM2.5 AQI Value</th>\n",
       "      <th>PM2.5 AQI Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  AQI Category  CO AQI Value  Ozone AQI Value  Ozone AQI Category  \\\n",
       "0      134             2             1               36                   0   \n",
       "1       23             0             1                5                   0   \n",
       "2       77             2             1               39                   0   \n",
       "3      126             0             1               34                   0   \n",
       "4      176             2             1               14                   0   \n",
       "\n",
       "   NO2 AQI Value  PM2.5 AQI Value  PM2.5 AQI Category  \n",
       "0              0               51                   2  \n",
       "1              1               41                   0  \n",
       "2              2               66                   2  \n",
       "3              0               20                   0  \n",
       "4             11               54                   2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/preprocessed_AQI_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2845, 7) (11384, 7)\n",
      "(2845,) (11384,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle the data before splitting\n",
    "df_shuffled = df.sample(frac=1, random_state=20)  \n",
    "X = df_shuffled.drop([\"AQI Category\"], axis=1)\n",
    "y = df_shuffled[\"AQI Category\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.8, random_state=22\n",
    ")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73      5327\n",
      "           1       0.63      0.57      0.60        42\n",
      "           2       0.69      0.46      0.55      4704\n",
      "           3       0.19      0.57      0.29       618\n",
      "           4       0.17      0.32      0.22       594\n",
      "           5       0.06      0.25      0.10        99\n",
      "\n",
      "    accuracy                           0.57     11384\n",
      "   macro avg       0.42      0.48      0.42     11384\n",
      "weighted avg       0.67      0.57      0.60     11384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_shifted = X - X.min() + 1  #to make sure all points are > 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shifted, y, test_size=0.8, random_state=22)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complement Naive Bayes: It is an adaptation of Multinomial NB where the complement of each class is used to calculate the model weights. So, this is suitable for imbalanced data sets and often outperforms the MNB on text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71      5327\n",
      "           1       0.00      0.00      0.00        42\n",
      "           2       0.66      0.07      0.13      4704\n",
      "           3       0.13      0.97      0.23       618\n",
      "           4       0.00      0.00      0.00       594\n",
      "           5       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.45     11384\n",
      "   macro avg       0.24      0.30      0.18     11384\n",
      "weighted avg       0.58      0.45      0.40     11384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shifted, y, test_size=0.8, random_state=22)\n",
    "\n",
    "cnb_classifier = ComplementNB()\n",
    "cnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cnb_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 1.5, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# hyperparams tuning\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0],  #smoothing param alpha\n",
    "    'fit_prior': [True, False],  \n",
    "}\n",
    "\n",
    "cnb_classifier = ComplementNB()\n",
    "grid_search = GridSearchCV(estimator=cnb_classifier, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5327\n",
      "           1       0.00      0.00      0.00        42\n",
      "           2       0.78      0.75      0.77      4704\n",
      "           3       0.32      0.40      0.35       618\n",
      "           4       0.00      0.00      0.00       594\n",
      "           5       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.80     11384\n",
      "   macro avg       0.33      0.36      0.34     11384\n",
      "weighted avg       0.75      0.80      0.77     11384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5327\n",
      "           1       0.00      0.00      0.00        42\n",
      "           2       0.78      0.75      0.77      4704\n",
      "           3       0.31      0.40      0.35       618\n",
      "           4       0.00      0.00      0.00       594\n",
      "           5       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.80     11384\n",
      "   macro avg       0.33      0.36      0.34     11384\n",
      "weighted avg       0.75      0.80      0.77     11384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_shifted, y, test_size=0.8, random_state=22)\n",
    "cnb_classifier = ComplementNB(alpha=0.1, fit_prior=True)\n",
    "cnb_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred = cnb_classifier.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score : 0.7969079409697821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc  = accuracy_score(y_pred, y_test)\n",
    "print(f'The accuracy score : {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores: [0.40470334 0.38666046 0.37422171 0.42144858 0.40055009 0.41906709\n",
      " 0.39955283]\n",
      "F1 mean: 0.4009 \n",
      "\n",
      "Precision scores: [0.59826145 0.58083462 0.64476458 0.68830024 0.65865429 0.67064869\n",
      " 0.58020296]\n",
      "Precision mean: 0.6317 \n",
      "\n",
      "Accuracy scores: [0.44226044 0.45208845 0.42997543 0.47044335 0.45812808 0.48768473\n",
      " 0.45812808]\n",
      "Accuracy mean: 0.457 \n",
      "\n",
      "Recall scores: [0.44226044 0.45208845 0.42997543 0.47044335 0.45812808 0.48768473\n",
      " 0.45812808]\n",
      "Recall mean: 0.457 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# here we define different scorers metrics\n",
    "scorer_f1 = make_scorer(f1_score, average='weighted')\n",
    "scorer_precision = make_scorer(precision_score, average='weighted', zero_division=1)\n",
    "scorer_recall = make_scorer(recall_score, average='weighted')\n",
    "scorer_accuracy = make_scorer(accuracy_score)\n",
    "\n",
    "# we save them in a dict for easier accessing\n",
    "scorers = {'f1': scorer_f1, 'precision': scorer_precision, 'accuracy': scorer_accuracy, 'recall': scorer_recall}\n",
    "scores_results : dict = {}\n",
    "for scorer_name, scorer in scorers.items():\n",
    "    scores = cross_val_score(cnb_classifier, X_train, y_train, cv=7, scoring=scorer)\n",
    "    print(f\"{scorer_name.capitalize()} scores:\", scores)\n",
    "    scores_results[scorer_name] = round(scores.mean(), 4)\n",
    "    print(f\"{scorer_name.capitalize()} mean:\", round(scores.mean(), 4),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44226044, 0.45208845, 0.42997543, 0.47044335, 0.45812808,\n",
       "       0.48768473, 0.45812808])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc= make_scorer(accuracy_score)\n",
    "scoores = cross_val_score(cnb_classifier, X_train, y_train, cv=7, scoring=acc_sc)\n",
    "scoores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.4009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.6317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.4570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Scores\n",
       "f1         0.4009\n",
       "precision  0.6317\n",
       "accuracy   0.4570\n",
       "recall     0.4570"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scores_df = pd.DataFrame.from_dict(scores_results, orient='index', columns=['Scores'])\n",
    "scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
