{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>AQI Value</th>\n",
       "      <th>AQI Category</th>\n",
       "      <th>CO AQI Value</th>\n",
       "      <th>CO AQI Category</th>\n",
       "      <th>Ozone AQI Value</th>\n",
       "      <th>Ozone AQI Category</th>\n",
       "      <th>NO2 AQI Value</th>\n",
       "      <th>NO2 AQI Category</th>\n",
       "      <th>PM2.5 AQI Value</th>\n",
       "      <th>PM2.5 AQI Category</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>10126</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>44.7444</td>\n",
       "      <td>44.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>10140</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2900</td>\n",
       "      <td>-44.4900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>10163</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>37.1667</td>\n",
       "      <td>15.1833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>10185</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0167</td>\n",
       "      <td>20.8833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>10243</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>16.1005</td>\n",
       "      <td>-88.8074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   City  AQI Value  AQI Category  CO AQI Value  CO AQI Category  \\\n",
       "0      130  10126         51             2             1                0   \n",
       "1       22  10140         41             0             1                0   \n",
       "2       75  10163         66             2             1                0   \n",
       "3      123  10185         34             0             1                0   \n",
       "4      166  10243         54             2             1                0   \n",
       "\n",
       "   Ozone AQI Value  Ozone AQI Category  NO2 AQI Value  NO2 AQI Category  \\\n",
       "0               36                   0              0                 0   \n",
       "1                5                   0              1                 0   \n",
       "2               39                   0              2                 0   \n",
       "3               34                   0              0                 0   \n",
       "4               14                   0             11                 0   \n",
       "\n",
       "   PM2.5 AQI Value  PM2.5 AQI Category      lat      lng  \n",
       "0               51                   2  44.7444  44.2031  \n",
       "1               41                   0  -5.2900 -44.4900  \n",
       "2               66                   2  37.1667  15.1833  \n",
       "3               20                   0  53.0167  20.8833  \n",
       "4               54                   2  16.1005 -88.8074  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/preprocessed_AQI_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2845, 13) (11384, 13)\n",
      "(2845,) (11384,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle the data before splitting\n",
    "df_shuffled = df.sample(frac=1, random_state=19)\n",
    "X = df_shuffled.drop([\"AQI Category\"], axis=1)\n",
    "y = df_shuffled[\"AQI Category\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.8, random_state=22\n",
    ")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70      5301\n",
      "           1       0.03      0.76      0.05        41\n",
      "           2       0.64      0.35      0.46      4741\n",
      "           3       0.21      0.28      0.24       618\n",
      "           4       0.10      0.24      0.14       588\n",
      "           5       0.04      0.20      0.06        95\n",
      "\n",
      "    accuracy                           0.49     11384\n",
      "   macro avg       0.29      0.42      0.28     11384\n",
      "weighted avg       0.62      0.49      0.54     11384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_shifted = X - X.min() + 1  # make sure all points are > 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_shifted, y, test_size=0.8, random_state=22\n",
    ")\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complement Naive Bayes: It is an adaptation of Multinomial NB where the complement of each class is used to calculate the model weights. So, this is suitable for imbalanced data sets and often outperforms the MNB on text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67      5301\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.62      0.13      0.22      4741\n",
      "           3       0.15      0.95      0.26       618\n",
      "           4       0.00      0.00      0.00       588\n",
      "           5       0.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.45     11384\n",
      "   macro avg       0.23      0.30      0.19     11384\n",
      "weighted avg       0.55      0.45      0.42     11384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_shifted, y, test_size=0.8, random_state=22\n",
    ")\n",
    "\n",
    "cnb_classifier = ComplementNB()\n",
    "cnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cnb_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.1, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# hyperparams tuning\n",
    "param_grid = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 1.5, 2.0],  # smoothing param alpha\n",
    "    \"fit_prior\": [True, False],\n",
    "}\n",
    "\n",
    "cnb_classifier = ComplementNB()\n",
    "grid_search = GridSearchCV(estimator=cnb_classifier, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      5301\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.80      0.83      0.82      4741\n",
      "           3       0.33      0.39      0.36       618\n",
      "           4       0.00      0.00      0.00       588\n",
      "           5       0.50      0.03      0.06        95\n",
      "\n",
      "    accuracy                           0.83     11384\n",
      "   macro avg       0.43      0.38      0.37     11384\n",
      "weighted avg       0.79      0.83      0.81     11384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      5301\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.80      0.83      0.82      4741\n",
      "           3       0.33      0.39      0.36       618\n",
      "           4       0.00      0.00      0.00       588\n",
      "           5       0.50      0.03      0.06        95\n",
      "\n",
      "    accuracy                           0.83     11384\n",
      "   macro avg       0.43      0.38      0.37     11384\n",
      "weighted avg       0.79      0.83      0.81     11384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/wissem/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_shifted, y, test_size=0.8, random_state=22\n",
    ")\n",
    "cnb_classifier = ComplementNB(alpha=0.1, fit_prior=True)\n",
    "cnb_classifier.fit(X_train_scaled, y_train)\n",
    "y_pred = cnb_classifier.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score : 0.8338896697118763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(f\"The accuracy score : {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores: [0.40965853 0.42782654 0.42375549 0.44858511 0.44583046 0.41600882\n",
      " 0.41148262]\n",
      "F1 mean: 0.4262 \n",
      "\n",
      "Precision scores: [0.60305118 0.58202182 0.55356814 0.58971916 0.63104935 0.61502466\n",
      " 0.60450048]\n",
      "Precision mean: 0.597 \n",
      "\n",
      "Accuracy scores: [0.47174447 0.45945946 0.44471744 0.49261084 0.4679803  0.44334975\n",
      " 0.45566502]\n",
      "Accuracy mean: 0.4622 \n",
      "\n",
      "Recall scores: [0.47174447 0.45945946 0.44471744 0.49261084 0.4679803  0.44334975\n",
      " 0.45566502]\n",
      "Recall mean: 0.4622 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "# here we define different scorers metrics\n",
    "scorer_f1 = make_scorer(f1_score, average=\"weighted\")\n",
    "scorer_precision = make_scorer(precision_score, average=\"weighted\", zero_division=1)\n",
    "scorer_recall = make_scorer(recall_score, average=\"weighted\")\n",
    "scorer_accuracy = make_scorer(accuracy_score)\n",
    "\n",
    "# Cwe save them in a dict for easier accessing\n",
    "scorers = {\n",
    "    \"f1\": scorer_f1,\n",
    "    \"precision\": scorer_precision,\n",
    "    \"accuracy\": scorer_accuracy,\n",
    "    \"recall\": scorer_recall,\n",
    "}\n",
    "scores_results: dict = {}\n",
    "for scorer_name, scorer in scorers.items():\n",
    "    scores = cross_val_score(cnb_classifier, X_train, y_train, cv=7, scoring=scorer)\n",
    "    print(f\"{scorer_name.capitalize()} scores:\", scores)\n",
    "    scores_results[scorer_name] = round(scores.mean(), 4)\n",
    "    print(f\"{scorer_name.capitalize()} mean:\", round(scores.mean(), 4), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47174447, 0.45945946, 0.44471744, 0.49261084, 0.4679803 ,\n",
       "       0.44334975, 0.45566502])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc = make_scorer(accuracy_score)\n",
    "scoores = cross_val_score(cnb_classifier, X_train, y_train, cv=7, scoring=acc_sc)\n",
    "scoores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.4262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.4622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.4622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Scores\n",
       "f1         0.4262\n",
       "precision  0.5970\n",
       "accuracy   0.4622\n",
       "recall     0.4622"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores_df = pd.DataFrame.from_dict(scores_results, orient=\"index\", columns=[\"Scores\"])\n",
    "scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
